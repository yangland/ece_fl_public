{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5794ad43-4546-4d84-82d5-4a0f252d61a1",
   "metadata": {},
   "source": [
    "# Adding malicious into the FL Avg, visualize the effects from malicious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebaa196-8bd3-417f-8f93-59bb1697d5c7",
   "metadata": {},
   "source": [
    "based on FoolsGold's code on malicious\n",
    "https://github.com/DistributedML/FoolsGold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "88c57c8f-b8dc-4538-9f18-84179ff37dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchmetrics.functional import kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9056f67c-9053-41e2-824a-5b3ec771611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data\")\n",
    "PATH = os.path.join(DATA_PATH, Path(\"mnist\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d5a893-19ec-4e16-8e67-8a7e66391d60",
   "metadata": {},
   "source": [
    "## Check the Mnist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fecdd797-0698-483b-8352-cf9218270f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\mnist'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9717c2ff-2ed0-40eb-949d-6280bc5dcffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'mnist_bad_1_7.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "793ab200-3064-468a-ae7b-eeeed3282541",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = np.load(os.path.join(PATH, Path(file_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ade06ada-9a74-4c91-ad16-ff6b9a1f3cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6742, 785)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4683ef8f-87bf-40ca-a331-f0fe25b65964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.57, 1.98, 0.57, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 1.98, 1.14, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.7 , 2.26, 0.29, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.14, 2.55, 1.14, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 2.26, 1.7 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.7 , 2.26, 0.29, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.86, 2.55, 0.86, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.57, 2.55, 1.41, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 2.55, 1.7 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 2.26, 1.7 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.7 , 2.26, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.41, 2.55, 0.86, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.86, 2.55, 1.41, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 2.55, 1.7 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.98, 1.98, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.41, 2.55, 0.29, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.86, 2.55, 1.14, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.86, 2.55, 1.7 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 2.55, 2.26, 0.57, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.14, 2.26, 0.29, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(linewidth=np.inf)\n",
    "testdata[6001][:784].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba9d3305-0545-4c93-955c-3f8fbeb1fd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "print(testdata[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d3991062-20fd-406f-8722-7c831027a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist0.npy (5923, 785)\n",
    "# mnist_bad_1_7.npy (6742, 785) # lable fliping, data(1) label(7)\n",
    "# mnist_uniform_0.npy (6000, 785)\n",
    "# mnist_train.npy (60000,785)\n",
    "# mnist_test.npy (10000, 785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "33875bf3-2466-430f-a1af-64208848c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(os.path.join(PATH, Path(\"mnist_train.npy\")))\n",
    "test_data = np.load(os.path.join(PATH, Path(\"mnist_test.npy\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41bf9c-c0ae-4932-8519-ede404bc1060",
   "metadata": {},
   "source": [
    "## Adjustable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "296ca420-3175-40c8-9477-cbd9a104fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clients = 40\n",
    "learning_rate = 0.01\n",
    "numEpoch = 10 # 4\n",
    "batch_size = 32\n",
    "momentum = 0.9\n",
    "dirichlet_alpha = 0.2\n",
    "num_classes = 10\n",
    "train_amount = 5400\n",
    "\n",
    "malicious_attack = False\n",
    "number_of_malicious = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09714724-a849-4dc7-94b2-20562e51cef9",
   "metadata": {},
   "source": [
    "## Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "92e549f8-159a-4bdf-b132-ea939719895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dictionary for clients Honest/Malicious:\n",
    "all_clients = {}\n",
    "malicious_names = np.random.randint(0, number_of_clients, number_of_malicious)\n",
    "malicious_names.sort()\n",
    "for i in range(number_of_clients):\n",
    "    if i in malicious_names:\n",
    "        all_clients['client'+str(i)] = 'Malicious'\n",
    "    else:\n",
    "        all_clients['client'+str(i)] = 'Honest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "57a19382-378b-4c56-80ae-c397a37cecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create IID or Non-IID dataset for all clients's training"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 122,
=======
   "execution_count": 67,
>>>>>>> parent of a8da15e (Revert "Update mnist_w_malicious.ipynb")
   "id": "224a549c-c161-4c78-930f-a015ef5245b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_shuffle_labels(y_data, seed, num_classes):\n",
    "    y_data=pd.DataFrame(y_data.cpu(),columns=[\"labels\"]) # create DF on all y values\n",
    "    y_data[\"i\"]=np.arange(len(y_data)) # create a global index\n",
    "    label_dict = dict()\n",
    "    for i in range(num_classes):\n",
    "        var_name=\"label\" + str(i)\n",
    "        label_info=y_data[y_data[\"labels\"]==i] # create an index for each class (only for MNIST)\n",
    "        np.random.seed(seed)\n",
    "        label_info=np.random.permutation(label_info)\n",
    "        label_info=pd.DataFrame(label_info, columns=[\"labels\",\"i\"])\n",
    "        label_dict.update({var_name: label_info })\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9c046bf1-14c8-4431-946d-e76d3656d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e6aaf701-2bf5-48af-bb55-48cf3fe9f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y lables to ints\n",
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8cf0360e-bc87-4eef-bad1-0cacf32dbb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "79268d0d-c3e4-48cd-8b26-0a10dc520ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5923,\n",
       " 1: 6742,\n",
       " 2: 5958,\n",
       " 3: 6131,\n",
       " 4: 5842,\n",
       " 5: 5421,\n",
       " 6: 5918,\n",
       " 7: 6265,\n",
       " 8: 5851,\n",
       " 9: 5949}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution in train data\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "335ef549-fe8e-4cc4-a933-29ca1308a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[1].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "267f2f73-4eab-4208-8b4b-66fb5f36fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount = train_amount = 4500\n",
    "# label_dict_train = split_and_shuffle_labels(y_data=y_train, seed=1, amount=train_amount) \n",
    "def get_subsamples_indices_new(label_dict, number_of_clients, amount, num_classes, NonIID = False, alpha=0.9):\n",
    "    sample_dict= dict()\n",
    "    batch_size=int(math.floor(amount/number_of_clients)) # 45\n",
    "    \n",
    "    if NonIID == False:\n",
    "        for i in range(number_of_clients): # create 100 number_of_clients\n",
    "            sample_name=\"sample\"+str(i)\n",
    "            dumb=pd.DataFrame()\n",
    "            # IID distribution, each number class gets same samples\n",
    "            for j in range(num_classes): # for each number 0 - 9\n",
    "                label_name=str(\"label\")+str(j)\n",
    "                a=label_dict[label_name][i*batch_size:(i+1)*batch_size] # get 45 record of one number \n",
    "                dumb=pd.concat([dumb,a], axis=0) # concat total 10 of them 0 - 9\n",
    "            dumb.reset_index(drop=True, inplace=True)    \n",
    "            sample_dict.update({sample_name: dumb}) # each sample 450, 100 samples\n",
    "    else:\n",
    "        # based of dirichlet distribution\n",
    "        #print(\"label_dict\", label_dict)\n",
    "        image_nums = []\n",
    "        sample_dict = {}\n",
    "        \n",
    "        for i in range (number_of_clients):\n",
    "            sample_name=\"sample\"+str(i)\n",
    "            sample_dict.update({sample_name: pd.DataFrame()})\n",
    "        \n",
    "        for label in range (num_classes):\n",
    "            image_num = []\n",
    "            sampled_probabilities = amount * np.random.dirichlet(\n",
    "                np.array(number_of_clients * [alpha]))\n",
    "            class_label_len = len(label_dict[str(\"label\")+str(label)])\n",
    "            # print(\"class_label_len\", class_label_len)\n",
    "            \n",
    "            for sample in range(number_of_clients):\n",
    "                # print(\"sample\", sample)\n",
    "                dumb2 = pd.DataFrame()\n",
    "                no_imgs = int(round(sampled_probabilities[sample]))\n",
    "                label_name=str(\"label\")+str(label)\n",
    "\n",
    "                sampled_list = label_dict[label_name][:min(class_label_len, no_imgs)]\n",
    "                image_num.append(len(sampled_list))\n",
    "                dumb2=pd.concat([dumb2, sampled_list], axis=0)\n",
    "                \n",
    "                class_label_len = class_label_len - len(sampled_list)\n",
    "                # print(\"user\", user)\n",
    "                # print(\"no_imgs\", no_imgs)\n",
    "                # print(\"class_label_len\", class_label_len)\n",
    "                sample_name=\"sample\"+str(sample)\n",
    "                image_nums.append(image_num)\n",
    "                # print(\"dumb2\", dumb2)\n",
    "                # print(\"label_name\", label_name)\n",
    "                # print(\"[dumb[label_name]\", dumb[label_name])\n",
    "                #dumb.reset_index(drop=True, inplace=True)\n",
    "                sample_dict[sample_name] = pd.concat([sample_dict[sample_name], dumb2])\n",
    "        # self.draw_dirichlet_plot(10, number_of_clients,image_nums, alpha)\n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "94d1f22f-7348-4435-b240-3124f631ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subsamples(sample_dict, x_data, y_data, x_name, y_name):\n",
    "    x_data_dict= dict()\n",
    "    y_data_dict= dict()\n",
    "    \n",
    "    for i in range(len(sample_dict)):  ### len(sample_dict)= number of samples 100\n",
    "        xname= x_name+str(i)\n",
    "        yname= y_name+str(i)\n",
    "        sample_name=\"sample\"+str(i)\n",
    "        \n",
    "        # use the global index to reconnect x and y\n",
    "        indices=np.sort(np.array(sample_dict[sample_name][\"i\"])) \n",
    "        \n",
    "        x_info= x_data[indices,:]\n",
    "        x_data_dict.update({xname : x_info})\n",
    "        \n",
    "        y_info= y_data[indices]\n",
    "        y_data_dict.update({yname : y_info})\n",
    "        \n",
    "    return x_data_dict, y_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fe832-c5a1-41c8-949e-e949a231a8a9",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7bfa6802-b1d8-477d-a500-b4c79134d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2nn, self).__init__()\n",
    "        self.fc1=nn.Linear(784,200)\n",
    "        self.fc2=nn.Linear(200,200)\n",
    "        self.fc3=nn.Linear(200,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8e2bd0e1-968e-428b-ae41-15e1223cfb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        prediction = output.argmax(dim=1, keepdim=True)\n",
    "        correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "        \n",
    "    return train_loss / len(train_loader), correct/len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3e10160f-8c18-4eb0-bea7-8684c5fea922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criterion(output, target).item()\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    correct /= len(test_loader.dataset)\n",
    "\n",
    "    return (test_loss, correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d01ba-1abf-45c7-bc5b-9dd24bedda21",
   "metadata": {},
   "source": [
    "## Functions for Rederated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5a85b90c-2d8a-46ba-afb1-c923306d0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_optimizer_criterion_dict(number_of_clients):\n",
    "    model_dict = dict()\n",
    "    optimizer_dict= dict()\n",
    "    criterion_dict = dict()\n",
    "    \n",
    "    for i in range(number_of_clients):\n",
    "        model_name=\"model\"+str(i)\n",
    "        model_info=Net2nn()\n",
    "        model_dict.update({model_name : model_info })\n",
    "        \n",
    "        optimizer_name=\"optimizer\"+str(i)\n",
    "        optimizer_info = torch.optim.SGD(model_info.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        optimizer_dict.update({optimizer_name : optimizer_info })\n",
    "        \n",
    "        criterion_name = \"criterion\"+str(i)\n",
    "        criterion_info = nn.CrossEntropyLoss()\n",
    "        criterion_dict.update({criterion_name : criterion_info})\n",
    "        \n",
    "    return model_dict, optimizer_dict, criterion_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e2df91fc-c638-493d-b805-0b85bb96db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_weights(model_dict, number_of_samples):\n",
    "   \n",
    "    fc1_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc1.weight.shape)\n",
    "    fc1_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc1.bias.shape)\n",
    "    \n",
    "    fc2_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc2.weight.shape)\n",
    "    fc2_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc2.bias.shape)\n",
    "    \n",
    "    fc3_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc3.weight.shape)\n",
    "    fc3_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc3.bias.shape)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "    \n",
    "        for i in range(number_of_samples):\n",
    "            fc1_mean_weight += model_dict[name_of_models[i]].fc1.weight.data.clone()\n",
    "            fc1_mean_bias += model_dict[name_of_models[i]].fc1.bias.data.clone()\n",
    "        \n",
    "            fc2_mean_weight += model_dict[name_of_models[i]].fc2.weight.data.clone()\n",
    "            fc2_mean_bias += model_dict[name_of_models[i]].fc2.bias.data.clone()\n",
    "        \n",
    "            fc3_mean_weight += model_dict[name_of_models[i]].fc3.weight.data.clone()\n",
    "            fc3_mean_bias += model_dict[name_of_models[i]].fc3.bias.data.clone()\n",
    "\n",
    "        \n",
    "        fc1_mean_weight =fc1_mean_weight/number_of_samples\n",
    "        fc1_mean_bias = fc1_mean_bias/ number_of_samples\n",
    "    \n",
    "        fc2_mean_weight =fc2_mean_weight/number_of_samples\n",
    "        fc2_mean_bias = fc2_mean_bias/ number_of_samples\n",
    "    \n",
    "        fc3_mean_weight =fc3_mean_weight/number_of_samples\n",
    "        fc3_mean_bias = fc3_mean_bias/ number_of_samples\n",
    "    \n",
    "    return fc1_mean_weight, fc1_mean_bias, fc2_mean_weight, fc2_mean_bias, fc3_mean_weight, fc3_mean_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "31d5af22-2d6d-4864-813b-1b84cd5181df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,model_dict, number_of_samples):\n",
    "    fc1_mean_weight, fc1_mean_bias, fc2_mean_weight, fc2_mean_bias, fc3_mean_weight, fc3_mean_bias = get_averaged_weights(model_dict, number_of_samples=number_of_samples)\n",
    "    with torch.no_grad():\n",
    "        main_model.fc1.weight.data = fc1_mean_weight.data.clone()\n",
    "        main_model.fc2.weight.data = fc2_mean_weight.data.clone()\n",
    "        main_model.fc3.weight.data = fc3_mean_weight.data.clone()\n",
    "\n",
    "        main_model.fc1.bias.data = fc1_mean_bias.data.clone()\n",
    "        main_model.fc2.bias.data = fc2_mean_bias.data.clone()\n",
    "        main_model.fc3.bias.data = fc3_mean_bias.data.clone() \n",
    "    return main_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "037e7f10-a60a-466e-bee0-4042e486d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples):\n",
    "    with torch.no_grad():\n",
    "        for i in range(number_of_samples):\n",
    "\n",
    "            model_dict[name_of_models[i]].fc1.weight.data =main_model.fc1.weight.data.clone()\n",
    "            model_dict[name_of_models[i]].fc2.weight.data =main_model.fc2.weight.data.clone()\n",
    "            model_dict[name_of_models[i]].fc3.weight.data =main_model.fc3.weight.data.clone() \n",
    "            \n",
    "            model_dict[name_of_models[i]].fc1.bias.data =main_model.fc1.bias.data.clone()\n",
    "            model_dict[name_of_models[i]].fc2.bias.data =main_model.fc2.bias.data.clone()\n",
    "            model_dict[name_of_models[i]].fc3.bias.data =main_model.fc3.bias.data.clone() \n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b685e2b1-6167-4928-9a38-061bf3428469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train_end_node_process_without_print(number_of_samples, sample_list, iteration, plot_indiv, plot_glob, layer, mode, global_table):\n",
    "    initial_result = create_similiarity_matrix(model_dict, layer, 0, mode)\n",
    "    # plot_matrix(initial_result, layer, iteration, mode, 0, file_location=\"Plots/\")\n",
    "    global_table.append([iteration, 0, layer, mode, initial_result])\n",
    "    \n",
    "    for epoch in range(1, numEpoch+1): \n",
    "        for i in range (number_of_samples): \n",
    "            train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n",
    "            train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n",
    "            test_dl = DataLoader(test_ds, batch_size= batch_size * 2)\n",
    "\n",
    "            model=model_dict[name_of_models[i]]\n",
    "            criterion=criterion_dict[name_of_criterions[i]]\n",
    "            optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "            \n",
    "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
    "            test_loss, test_accuracy = validation(model, test_dl, criterion)\n",
    "        \n",
    "        if plot_indiv is True:\n",
    "            for sample in sample_list:\n",
    "                plot_node_weights(model_dict, sample[0], sample[1], iteration)\n",
    "                \n",
    "        if plot_glob is True:\n",
    "            iteration_result = create_similiarity_matrix(model_dict, layer, iteration, mode)\n",
    "            # plot_matrix(iteration_result, layer, iteration, mode, epoch, file_location=\"Plots/\")\n",
    "            global_table.append([iteration, epoch, layer, mode, iteration_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d4cdb-1a26-435b-94a3-b7d92b671b83",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "99dda967-8d6a-4551-8c43-749e5e724723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global matrix\n",
    "def plot_matrix(result, layer, iteration, mode, epoch, vmin, vmax, num_ticks, file_location=\"Plots/\"):\n",
    "    matplotlib.use('Agg')\n",
    "    labels = list(range(0, number_of_samples))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,15))\n",
    "    # cax = ax.matshow(result, interpolation='nearest')\n",
    "    if mode == 'cos':\n",
    "        colormap = 'OrRd'\n",
    "    elif mode == 'l2':\n",
    "        colormap = 'YlGnBu'\n",
    "    \n",
    "    cax = ax.imshow(result, vmin = vmin, vmax = v_max, cmap=colormap, interpolation='nearest') # cmap='YlGnBu', 'OrRd'    \n",
    "    # ax.grid(True)\n",
    "    plt.title('100 FL Clients Similarity Matrix IID' + \" \" + str(mode) + \" \" + \"iter\" + str(iteration) + \"_\" + \"epoch\" + str(epoch), fontsize = 15)\n",
    "    plt.xticks(range(number_of_samples), labels, rotation=90);\n",
    "    plt.yticks(range(number_of_samples), labels);\n",
    "    # ticks = np.linspace(vmin, vmax, num_ticks)\n",
    "    ticks = np.arange(v_min, v_max, round((v_max - v_min)/(num_ticks-1), 2))\n",
    "    ticks = np.append(ticks, v_max)\n",
    "    cbar = fig.colorbar(cax, ax=ax)\n",
    "\n",
    "    font_size = 10 # Adjust as appropriate.\n",
    "    cbar.set_ticks(ticks)\n",
    "    cbar.ax.tick_params(labelsize=font_size)\n",
    "    \n",
    "    # plt.show()\n",
    "    \n",
    "    # create a time stamp\n",
    "    today = date.today().strftime('%Y%m%d')\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H-%M-%S\")\n",
    "    \n",
    "    plt_name = \"Glob\" + \"_\" + layer + \"_\"  + \"I\" + str(iteration) + \"_\" +\\\n",
    "                \"E\" + str(epoch) + \"_\" + str(today) + \"_\" + str(current_time) + \".png\"\n",
    "    \n",
    "    node_folder = file_location + layer + \"_\" + str(mode)\n",
    "    \n",
    "    if not os.path.exists(node_folder):\n",
    "        os.makedirs(node_folder)\n",
    "    \n",
    "    plt.savefig(node_folder + '/' + plt_name)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0350f2d4-bef2-4d85-8bac-59b3b8171cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual node weights and bias\n",
    "def plot_node_weights(model_dict, layer, selected_weight, iteration, file_location=\"Plots/\"):\n",
    "    # create an array of the weight values|\n",
    "    sample_weights = []\n",
    "    sample_bias = []\n",
    "    for i in range (number_of_samples):\n",
    "        current_model = \"model\" + str(i)\n",
    "        w_local = getattr(model_dict[current_model], layer).weight[selected_weight[0],selected_weight[1]].detach().numpy()\n",
    "        b_local = getattr(model_dict[current_model], layer).bias[selected_weight[0]].detach().numpy()\n",
    "        \n",
    "        sample_weights.append(w_local.tolist())\n",
    "        sample_bias.append(b_local.tolist())\n",
    "\n",
    "    num_bins = int(number_of_samples/4)\n",
    "\n",
    "    # process the data with GaussianMixture model\n",
    "    sample_weights = np.asarray(sample_weights)\n",
    "    sample_weights = sample_weights.reshape(len(sample_weights), 1)\n",
    "    sample_bias = np.asarray(sample_bias)\n",
    "    sample_bias = sample_bias.reshape(len(sample_bias), 1)    \n",
    "\n",
    "    # Create a histgram\n",
    "    # fig, ax = plt.subplots()\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, sharey=False, figsize=(10, 15))\n",
    "\n",
    "    n, bins, patches = ax1.hist(sample_weights, num_bins, \n",
    "                            density = 1, \n",
    "                            color ='darkolivegreen',\n",
    "                            alpha = 0.7)\n",
    "    \n",
    "    mu1 = np.mean(sample_weights)\n",
    "    fig.set_facecolor(\"lightgray\")\n",
    "    ax1.axvline(mu1, color='blue', linestyle='dashed', linewidth=1)\n",
    "    # min_ylim, max_ylim = plt.ylim()\n",
    "    plt.suptitle('IID Layer of: ' + layer + ', Random Weight: ' +  str(selected_weight) + ', Iter ' + str(iteration))\n",
    "    ax1.set_title('Weights Mean: {:.6f}'.format(mu1))\n",
    "    \n",
    "    n, bins, patches = ax2.hist(sample_bias, num_bins, \n",
    "                            density = 1, \n",
    "                            color ='brown',\n",
    "                            alpha = 0.7)\n",
    "    \n",
    "    mu2 = np.mean(sample_bias)\n",
    "    ax2.axvline(mu2, color='blue', linestyle='dashed', linewidth=1)\n",
    "    ax2.set_title('Bias Mean: {:.6f}'.format(mu2))    \n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    # create a time stamp\n",
    "    today = date.today().strftime('%Y%m%d')\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H-%M-%S\")\n",
    "    \n",
    "    # plt.show() \n",
    "    plt_name = layer + \"_\" + str(selected_weight[0]) + \"_\" + str(selected_weight[1]) + \"_I_\" + \\\n",
    "    str(iteration) + \"_\" + str(today) + \"_\" + str(current_time) + \".png\"\n",
    "    \n",
    "    node_folder = file_location + layer + \"_\" + str(selected_weight[0]) + \"_\" + str(selected_weight[1])\n",
    "    \n",
    "    if not os.path.exists(node_folder):\n",
    "        os.makedirs(node_folder)\n",
    "    \n",
    "    plt.savefig(node_folder + '/' + plt_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9fba59ef-aaef-4820-b52a-8d5915b3ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling based on parameters on layer selection\n",
    "def random_sampling_nodes(model, each_layer_sample_num):\n",
    "    layers = []\n",
    "    for name, layer in model.named_modules():\n",
    "        if name != \"\":\n",
    "            dnn_layer = getattr(model, name)\n",
    "            layers.append([name, [dnn_layer.weight.size()[0], dnn_layer.weight.size()[1]], dnn_layer.bias.size()[0]])\n",
    "    print(*layers,sep='\\n')\n",
    "    \n",
    "    if len(each_layer_sample_num)!=len(layers):\n",
    "        print(\"each_layer_sample_num list's length not equal to model layer list\")\n",
    "        return(-1)\n",
    "    else:\n",
    "        weights_sample = []\n",
    "        for i in range(len(layers)):\n",
    "            for j in range (each_layer_sample_num[i]):\n",
    "                random_weight = [np.random.randint(layers[i][1][0]), np.random.randint(layers[i][1][1])]\n",
    "                print(\"random_weight:\", random_weight)\n",
    "                weights_sample.append([layers[i][0], random_weight])\n",
    "    return weights_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e00c979b-328c-487f-94b3-15f1226aba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances Matrixes\n",
    "def l2dist(p1, p2):\n",
    "    \"\"\"L2 distance between p1, p2, each of which is a tensor\"\"\"\n",
    "    \n",
    "    return torch.dist(p1, p2, p=2)\n",
    "    \n",
    "\n",
    "def cosine_similarity(grad1, grad2, normalized=False):\n",
    "\t\"\"\"\n",
    "\tInput: two sets of gradients of the same shape\n",
    "\tOutput range: [-1, 1]\n",
    "\t\"\"\"\n",
    "\n",
    "\tcos_sim = F.cosine_similarity(torch.flatten(grad1), torch.flatten(grad2), 0, 1e-10) \n",
    "\tif normalized:\n",
    "\t\treturn (cos_sim + 1) / 2.0\n",
    "\telse:\n",
    "\t\treturn cos_sim\n",
    "# KLD relative entripy\n",
    "# kl_divergence(q, p) q, p as tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "63b16354-22f2-40f8-8c8a-216384746456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the similiarity matrix of the avg distance or similiarity between clients\n",
    "def create_similiarity_matrix(model_dict, layer, iteration, mode):\n",
    "    # create an array of the weight values\n",
    "    if mode not in [\"l2\", \"cos\"]:\n",
    "        raise Error(\"model has to be in 'l2', 'cos'.\")\n",
    "    \n",
    "    sample_weights = []\n",
    "    for i in range (number_of_samples):\n",
    "        current_model = \"model\" + str(i)\n",
    "        w_i = getattr(model_dict[current_model], layer).weight\n",
    "        sample_weights.append(w_i)\n",
    "    \n",
    "    resultTable = []\n",
    "    for i in range(len(sample_weights)):\n",
    "        distances = []\n",
    "        for j in range(len(sample_weights)):\n",
    "            if mode == \"l2\":\n",
    "                distances.append(l2dist(sample_weights[i], sample_weights[j]).item())\n",
    "            elif mode == \"cos\":\n",
    "                distances.append(cosine_similarity(sample_weights[i], sample_weights[j], False).item())\n",
    "        resultTable.append(distances)\n",
    "        \n",
    "    # print(\"resultTable[0]\", resultTable[0])    \n",
    "    return(resultTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1963f8ad-43be-43d0-9bf6-42946cd76b09",
   "metadata": {},
   "source": [
    "## Create the centralized model and distribute model and data to clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2ea04eac-9b0b-4a0e-83a6-e21e9aa956c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_model = Net2nn()\n",
    "centralized_optimizer = torch.optim.SGD(centralized_model.parameters(), lr=0.01, momentum=0.9)\n",
    "centralized_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a4a0a8c8-db82-49d5-8b06-6bf2418a9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets for training and server validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "57ca9226-96d0-4f00-b153-f416589fc50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_train=split_and_shuffle_labels(y_data=y_train, seed=1, num_classes = num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4dbe48fb-684a-4212-9202-4edb7b4b401d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>51224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>49821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>55014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>12442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>29995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6260</th>\n",
       "      <td>7</td>\n",
       "      <td>8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>7</td>\n",
       "      <td>49363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6262</th>\n",
       "      <td>7</td>\n",
       "      <td>37550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>7</td>\n",
       "      <td>2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>7</td>\n",
       "      <td>49110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6265 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels      i\n",
       "0          7  51224\n",
       "1          7  49821\n",
       "2          7  55014\n",
       "3          7  12442\n",
       "4          7  29995\n",
       "...      ...    ...\n",
       "6260       7   8235\n",
       "6261       7  49363\n",
       "6262       7  37550\n",
       "6263       7   2070\n",
       "6264       7  49110\n",
       "\n",
       "[6265 rows x 2 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict_train['label7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2516a04f-e237-47e0-b0c7-b1477fce0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dict_train = get_subsamples_indices_new(label_dict=label_dict_train, number_of_clients=number_of_clients, amount=train_amount, num_classes=num_classes, NonIID=False, alpha = dirichlet_alpha)\n",
    "x_train_dict, y_train_dict = create_subsamples(sample_dict=sample_dict_train, x_data=x_train, y_data=y_train, x_name=\"x_train\", y_name=\"y_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2be44762-94a0-4556-83ec-f68854265fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    135\n",
       "1    135\n",
       "2    135\n",
       "3    135\n",
       "4    135\n",
       "5    135\n",
       "6    135\n",
       "7    135\n",
       "8    135\n",
       "9    135\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dict_train['sample0']['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "81b7f6cd-1bca-486c-845f-a348176239aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>26967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>41509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>15463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>9</td>\n",
       "      <td>48567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>9</td>\n",
       "      <td>54555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>9</td>\n",
       "      <td>34142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>9</td>\n",
       "      <td>7422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>9</td>\n",
       "      <td>54238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels      i\n",
       "0          0   2944\n",
       "1          0  26967\n",
       "2          0  41509\n",
       "3          0  53492\n",
       "4          0  15463\n",
       "...      ...    ...\n",
       "1345       9  48567\n",
       "1346       9  54555\n",
       "1347       9  34142\n",
       "1348       9   7422\n",
       "1349       9  54238\n",
       "\n",
       "[1350 rows x 2 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dict_train['sample0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "85add606-6dcb-4e83-a2f8-68afef0484ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_train0': array([4, 8, 9, ..., 5, 5, 6]),\n",
       " 'y_train1': array([9, 5, 6, ..., 5, 3, 1]),\n",
       " 'y_train2': array([3, 3, 0, ..., 3, 7, 2]),\n",
       " 'y_train3': array([7, 5, 7, ..., 4, 4, 7]),\n",
       " 'y_train4': array([3, 1, 1, ..., 2, 7, 7]),\n",
       " 'y_train5': array([4, 8, 7, ..., 0, 1, 9]),\n",
       " 'y_train6': array([9, 2, 0, ..., 9, 8, 7]),\n",
       " 'y_train7': array([5, 1, 3, ..., 8, 0, 4]),\n",
       " 'y_train8': array([7, 4, 5, ..., 6, 2, 9]),\n",
       " 'y_train9': array([9, 9, 4, ..., 8, 2, 7]),\n",
       " 'y_train10': array([0, 6, 4, ..., 4, 7, 7]),\n",
       " 'y_train11': array([9, 5, 2, ..., 2, 5, 5]),\n",
       " 'y_train12': array([3, 1, 7, ..., 9, 5, 7]),\n",
       " 'y_train13': array([7, 5, 3, ..., 0, 6, 4]),\n",
       " 'y_train14': array([7, 1, 3, ..., 7, 7, 4]),\n",
       " 'y_train15': array([9, 0, 6, ..., 4, 6, 0]),\n",
       " 'y_train16': array([3, 9, 1, ..., 9, 5, 2]),\n",
       " 'y_train17': array([7, 3, 2, ..., 3, 7, 1]),\n",
       " 'y_train18': array([9, 7, 2, ..., 5, 7, 7]),\n",
       " 'y_train19': array([9, 3, 2, ..., 3, 5, 2]),\n",
       " 'y_train20': array([1, 7, 3, ..., 2, 1, 8]),\n",
       " 'y_train21': array([7, 3, 3, ..., 1, 1, 5]),\n",
       " 'y_train22': array([1, 0, 4, ..., 7, 7, 5]),\n",
       " 'y_train23': array([9, 2, 1, ..., 1, 0, 3]),\n",
       " 'y_train24': array([3, 1, 1, ..., 4, 3, 6]),\n",
       " 'y_train25': array([7, 9, 2, ..., 1, 5, 6]),\n",
       " 'y_train26': array([5, 3, 0, ..., 5, 7, 5]),\n",
       " 'y_train27': array([5, 7, 4, ..., 1, 5, 9]),\n",
       " 'y_train28': array([9, 0, 6, ..., 3, 5, 5]),\n",
       " 'y_train29': array([4, 4, 8, ..., 8, 3, 4]),\n",
       " 'y_train30': array([5, 9, 0, ..., 7, 8, 5]),\n",
       " 'y_train31': array([9, 2, 4, ..., 8, 4, 6]),\n",
       " 'y_train32': array([5, 3, 7, ..., 7, 9, 2]),\n",
       " 'y_train33': array([4, 9, 2, ..., 4, 3, 7]),\n",
       " 'y_train34': array([3, 5, 1, ..., 4, 2, 4]),\n",
       " 'y_train35': array([7, 6, 4, ..., 4, 9, 7]),\n",
       " 'y_train36': array([9, 0, 2, ..., 2, 9, 1]),\n",
       " 'y_train37': array([3, 4, 7, ..., 5, 5, 9]),\n",
       " 'y_train38': array([1, 7, 9, ..., 5, 7, 1]),\n",
       " 'y_train39': array([9, 0, 6, ..., 4, 8, 4])}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b3c74-3ce4-4623-aa37-50e912a26f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dict['x_train0'][1].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9380c1e2-db45-4f50-9e1d-6fb56172c3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client0': 'Malicious',\n",
       " 'client1': 'Honest',\n",
       " 'client2': 'Honest',\n",
       " 'client3': 'Honest',\n",
       " 'client4': 'Honest',\n",
       " 'client5': 'Honest',\n",
       " 'client6': 'Honest',\n",
       " 'client7': 'Honest',\n",
       " 'client8': 'Honest',\n",
       " 'client9': 'Honest',\n",
       " 'client10': 'Malicious',\n",
       " 'client11': 'Malicious',\n",
       " 'client12': 'Honest',\n",
       " 'client13': 'Honest',\n",
       " 'client14': 'Malicious',\n",
       " 'client15': 'Malicious',\n",
       " 'client16': 'Honest',\n",
       " 'client17': 'Honest',\n",
       " 'client18': 'Honest',\n",
       " 'client19': 'Honest',\n",
       " 'client20': 'Honest',\n",
       " 'client21': 'Honest',\n",
       " 'client22': 'Honest',\n",
       " 'client23': 'Honest',\n",
       " 'client24': 'Honest',\n",
       " 'client25': 'Honest',\n",
       " 'client26': 'Honest',\n",
       " 'client27': 'Honest',\n",
       " 'client28': 'Malicious',\n",
       " 'client29': 'Honest',\n",
       " 'client30': 'Honest',\n",
       " 'client31': 'Honest',\n",
       " 'client32': 'Honest',\n",
       " 'client33': 'Malicious',\n",
       " 'client34': 'Malicious',\n",
       " 'client35': 'Honest',\n",
       " 'client36': 'Honest',\n",
       " 'client37': 'Malicious',\n",
       " 'client38': 'Honest',\n",
       " 'client39': 'Malicious'}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a7274d26-8db4-4e9d-9ab1-39c437ef5ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5,  6, 16, 20, 21, 22, 29, 33, 39])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malicious_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9843712-dfa6-4bd7-9be5-4e8e1118446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for malicious clients, training with malicious data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "bb917b33-c482-4b6e-abdc-49608239358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_malicious_datasets(x_train_dict, y_train_dict, malicious_names, mode, from_label, to_label):\n",
    "    x_train_m_dict = {}\n",
    "    y_train_m_dict = {}\n",
    "    if mode == 'untargeted':\n",
    "        for i in malicious_names:\n",
    "            # keep x train unchanged\n",
    "            x_train_m_dict[\"x_train_m_\"+str(i)] = x_train_dict[\"x_train\"+str(i)]\n",
    "            y_untargeted = []\n",
    "            for j in range(len(y_train_dict['y_train0'])):\n",
    "                # y = existed y label + 1, 1->2, ... , 9 -> 1\n",
    "                y_untargeted.append(y_train_dict['y_train'+ str(i)][j] + 1 % 10)\n",
    "                y_train_m_dict[\"y_train_m_\"+str(i)] = np.asarray(y_untargeted)\n",
    "    if mode == 'label_flipping':\n",
    "        for i in malicious_names:\n",
    "            # keep x train unchanged\n",
    "            x_train_m_dict[\"x_train_m_\"+str(i)] = x_train_dict[\"x_train\"+str(i)]\n",
    "            y_flipped = []\n",
    "            for j in range(len(y_train_dict['y_train0'])):\n",
    "                # if y is from_label, update it to to_label, vice versa\n",
    "                current_label = y_train_dict['y_train'+ str(i)][j]\n",
    "                if current_label not in [from_label, to_label]:\n",
    "                    y_flipped.append(current_label)\n",
    "                else:\n",
    "                    if current_label == from_label:\n",
    "                        y_flipped.append(to_label)\n",
    "                    elif current_label == to_label:\n",
    "                        y_flipped.append(from_label)\n",
    "                y_train_m_dict[\"y_train_m_\"+str(i)] = np.asarray(y_flipped)\n",
    "    if mode == 'backdoor':\n",
    "        for i in malicious_names:\n",
    "            client_x = []\n",
    "            client_y = []\n",
    "            for j in range(len(x_train_dict['x_train0'])):\n",
    "                current_label = y_train_dict['y_train'+ str(i)][j]\n",
    "                current_x = x_train_dict['x_train'+ str(i)][j]\n",
    "                if current_label == from_label:\n",
    "                    # Set pixel #783 to white (the brightest white in picture)                    \n",
    "                    current_x[783] = np.max(current_x)\n",
    "                    client_x.append(current_x)\n",
    "                    client_y.append(to_label)\n",
    "                else:\n",
    "                    client_x.append(current_x)\n",
    "                    client_y.append(current_label)                    \n",
    "            x_train_m_dict[\"x_train_m_\"+str(i)] = np.asarray(client_x) \n",
    "            y_train_m_dict[\"y_train_m_\"+str(i)] = np.asarray(client_y) \n",
    "    return (x_train_m_dict, y_train_m_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "03dbd4e3-d16c-4002-835c-e2cad3b765ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_m_dict, y_train_m_dict = create_malicious_datasets(x_train_dict, y_train_dict, malicious_names, 'backdoor', 1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e9ed0cb2-8a9d-454c-b094-66b184838c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.64, 2.55, 2.53, 2.53, 2.53, 2.53, 0.6 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 1.91, 2.53, 2.52, 2.52, 2.52, 2.52, 0.71, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.83, 2.52, 2.53, 2.52, 2.3 , 2.23, 2.52, 2.14, 0.23, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 2.29, 2.52, 2.51, 1.34, 0.32, 0.16, 1.13, 0.88, 0.  , 0.42, 1.07, 0.03, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.7 , 2.46, 2.52, 1.83, 0.  , 0.  , 0.  , 0.  , 0.47, 1.58, 2.42, 2.52, 0.98, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.89, 2.52, 2.17, 0.  , 0.  , 0.  , 0.14, 1.02, 2.38, 2.52, 2.52, 2.52, 0.98, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 2.17, 2.52, 1.31, 0.  , 0.  , 0.13, 1.17, 2.52, 2.52, 2.52, 2.52, 2.16, 0.08, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 2.17, 2.52, 1.31, 0.  , 0.1 , 1.76, 2.52, 2.52, 2.52, 2.52, 2.15, 0.31, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 2.17, 2.52, 1.31, 1.16, 2.31, 2.52, 2.52, 2.52, 2.52, 2.16, 0.31, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 2.17, 2.52, 2.47, 2.53, 2.52, 2.52, 2.52, 1.65, 0.4 , 0.08, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.51, 2.37, 2.53, 2.53, 2.55, 2.53, 2.46, 1.37, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 1.17, 2.32, 2.52, 2.52, 2.52, 2.52, 2.16, 0.41, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.24, 2.52, 2.52, 2.52, 2.52, 2.52, 2.52, 1.66, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.06, 2.25, 2.52, 2.52, 2.52, 2.1 , 2.48, 2.52, 1.43, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.61, 1.79, 2.52, 2.52, 2.52, 1.62, 0.1 , 2.29, 2.52, 2.41, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.47, 2.52, 2.52, 2.52, 2.  , 0.88, 0.12, 0.  , 1.37, 2.52, 2.41, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 1.32, 2.52, 2.52, 2.52, 0.72, 0.  , 0.  , 0.33, 2.14, 2.52, 1.43, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 2.37, 2.52, 2.52, 2.52, 1.4 , 0.97, 1.37, 2.3 , 2.52, 2.52, 0.17, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 2.53, 2.52, 2.52, 2.52, 2.52, 2.52, 2.52, 2.52, 1.53, 0.29, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.75, 1.43, 2.52, 2.52, 2.52, 2.52, 2.52, 2.52, 0.23, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_m_dict['x_train_m_0'][1].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1ddad6bf-23f6-4efb-b93a-80e8973dc65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_m_dict['y_train_m_0'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0420b9a8-cbce-40ff-9b94-2a75ee780146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_train_m_dict['y_train_m_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a6de6-1c5a-4c16-9f86-b1bfc43bae21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
