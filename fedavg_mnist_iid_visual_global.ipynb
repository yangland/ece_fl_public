{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#6B49F5> A Simple Implementation of FedAvg with PyTorch </font> \n",
    "Yang updated\n",
    "Please see https://towardsdatascience.com/federated-learning-a-simple-implementation-of-fedavg-federated-averaging-with-pytorch-90187c9c9577 for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the selected layer's L2 or cos distance between all clients\n",
    "* In IID and Non-IID dataset (2 classes group special case)\n",
    "* Non-IID in dirichlet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import cm as cm\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime \n",
    "from datetime import date\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from CKA import CKA, CudaCKA\n",
    "\n",
    "pd.options.display.float_format = \"{:,.4f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download data set\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "# PATH = os.join.path(p1, p2)\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), (x_test, y_test)) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the dataset size\n",
    "x_train.shape, y_train.shape , x_valid.shape, y_valid.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\fl37\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(8,8,figsize=(8,8))\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        num_index = np.random.randint(len(x_train))\n",
    "        axes[i,j].imshow(x_train[num_index].reshape((28,28)), cmap=\"gray\")\n",
    "        axes[i,j].axis(\"off\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 8, 4, 8], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check how many of each tag are**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 >> train: 4932 , valid: 991 , test: 980 , total: 6903\n",
      "1 >> train: 5678 , valid: 1064 , test: 1135 , total: 7877\n",
      "2 >> train: 4968 , valid: 990 , test: 1032 , total: 6990\n",
      "3 >> train: 5101 , valid: 1030 , test: 1010 , total: 7141\n",
      "4 >> train: 4859 , valid: 983 , test: 982 , total: 6824\n",
      "5 >> train: 4506 , valid: 915 , test: 892 , total: 6313\n",
      "6 >> train: 4951 , valid: 967 , test: 958 , total: 6876\n",
      "7 >> train: 5175 , valid: 1090 , test: 1028 , total: 7293\n",
      "8 >> train: 4842 , valid: 1009 , test: 974 , total: 6825\n",
      "9 >> train: 4988 , valid: 961 , test: 1009 , total: 6958\n",
      "y_train_total= 50000\n",
      "y_valid_total= 10000\n",
      "y_test_total= 10000\n",
      "total= 70000\n"
     ]
    }
   ],
   "source": [
    "# Let's check how many of each tag are.\n",
    "y_train_total=0\n",
    "y_valid_total=0\n",
    "y_test_total=0\n",
    "total=0\n",
    "for i in range(10):\n",
    "    print(i,\">> train:\", sum(y_train==i), \", valid:\", sum(y_valid==i), \n",
    "          \", test:\", sum(y_test==i), \", total:\", sum(y_train==i)+sum(y_valid==i)+sum(y_test==i) )\n",
    "    y_train_total=y_train_total + sum(y_train==i)\n",
    "    y_valid_total=y_valid_total + sum(y_valid==i)\n",
    "    y_test_total=y_test_total + sum(y_test==i)\n",
    "    total=total+sum(y_train==i)+sum(y_valid==i)+sum(y_test==i)\n",
    "    \n",
    "print(\"y_train_total=\", y_train_total) \n",
    "print(\"y_valid_total=\", y_valid_total) \n",
    "print(\"y_test_total=\", y_test_total)\n",
    "print(\"total=\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_shuffle_labels(y_data, seed, amount):\n",
    "    y_data=pd.DataFrame(y_data,columns=[\"labels\"])\n",
    "    y_data[\"i\"]=np.arange(len(y_data))\n",
    "    label_dict = dict()\n",
    "    for i in range(10):\n",
    "        var_name=\"label\" + str(i)\n",
    "        label_info=y_data[y_data[\"labels\"]==i]\n",
    "        np.random.seed(seed)\n",
    "        label_info=np.random.permutation(label_info)\n",
    "        label_info=label_info[0:amount]\n",
    "        label_info=pd.DataFrame(label_info, columns=[\"labels\",\"i\"])\n",
    "        label_dict.update({var_name: label_info })\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsamples_indices(label_dict, number_of_samples, amount, NonIID = False):\n",
    "    sample_dict= dict()\n",
    "    batch_size=int(math.floor(amount/number_of_samples)) # 45\n",
    "    \n",
    "    # sample 5 out of the 10 figures, two groups a and b\n",
    "    non_iid_classes_a = random.sample([*range(0,10,1)], 5)\n",
    "    non_iid_classes_b = list(set([*range(0,10,1)]) - set(non_iid_classes_a))\n",
    "    for i in range(number_of_samples): # create 100 number_of_samples\n",
    "        sample_name=\"sample\"+str(i)\n",
    "        dumb=pd.DataFrame()\n",
    "        if NonIID:\n",
    "            # Non-IID distribution, each sample only gets 5 classes\n",
    "            if i % 2 == 0:\n",
    "                # i is even, use group a's class\n",
    "                for j in non_iid_classes_a:\n",
    "                    label_name=str(\"label\")+str(j)\n",
    "                    a=label_dict[label_name][i*batch_size:(i+2)*batch_size]\n",
    "                    dumb=pd.concat([dumb,a], axis=0)\n",
    "            else:    \n",
    "                for j in non_iid_classes_b:\n",
    "                    label_name=str(\"label\")+str(j)\n",
    "                    a=label_dict[label_name][i*batch_size:(i+2)*batch_size]\n",
    "                    dumb=pd.concat([dumb,a], axis=0)         \n",
    "        else:\n",
    "            # IID distribution, each number class gets same samples\n",
    "            for j in range(10): # for each number 0 - 9\n",
    "                label_name=str(\"label\")+str(j)\n",
    "                a=label_dict[label_name][i*batch_size:(i+1)*batch_size] # get 45 record of one number \n",
    "                dumb=pd.concat([dumb,a], axis=0) # concat total 10 of them 0 - 9\n",
    "        dumb.reset_index(drop=True, inplace=True)    \n",
    "        sample_dict.update({sample_name: dumb}) # each sample 450, 100 samples\n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsamples_indices_new(label_dict, number_of_samples, amount, NonIID, alpha):\n",
    "    sample_dict= dict()\n",
    "    batch_size=int(math.floor(amount/number_of_samples)) # 45\n",
    "    no_classes = 10\n",
    "    \n",
    "    if NonIID == False:\n",
    "        for i in range(number_of_samples): # create 100 number_of_samples\n",
    "            sample_name=\"sample\"+str(i)\n",
    "            dumb=pd.DataFrame()\n",
    "            # IID distribution, each number class gets same samples\n",
    "            for j in range(no_classes): # for each number 0 - 9\n",
    "                label_name=str(\"label\")+str(j)\n",
    "                a=label_dict[label_name][i*batch_size:(i+1)*batch_size] # get 45 record of one number \n",
    "                dumb=pd.concat([dumb,a], axis=0) # concat total 10 of them 0 - 9\n",
    "            dumb.reset_index(drop=True, inplace=True)    \n",
    "            sample_dict.update({sample_name: dumb}) # each sample 450, 100 samples\n",
    "    else:\n",
    "        # based of dirichlet distribution\n",
    "        #print(\"label_dict\", label_dict)\n",
    "        image_nums = []\n",
    "        sample_dict = {}\n",
    "        \n",
    "        for i in range (number_of_samples):\n",
    "            sample_name=\"sample\"+str(i)\n",
    "            sample_dict.update({sample_name: pd.DataFrame()})\n",
    "        \n",
    "        for label in range (no_classes):\n",
    "            image_num = []\n",
    "            sampled_probabilities = amount * np.random.dirichlet(\n",
    "                np.array(number_of_samples * [alpha]))\n",
    "            class_label_len = len(label_dict[str(\"label\")+str(label)])\n",
    "            # print(\"class_label_len\", class_label_len)\n",
    "            \n",
    "            for sample in range(number_of_samples):\n",
    "                # print(\"sample\", sample)\n",
    "                dumb2 = pd.DataFrame()\n",
    "                no_imgs = int(round(sampled_probabilities[sample]))\n",
    "                label_name=str(\"label\")+str(label)\n",
    "\n",
    "                sampled_list = label_dict[label_name][:min(class_label_len, no_imgs)]\n",
    "                image_num.append(len(sampled_list))\n",
    "                dumb2=pd.concat([dumb2, sampled_list], axis=0)\n",
    "                \n",
    "                class_label_len = class_label_len - len(sampled_list)\n",
    "                # print(\"user\", user)\n",
    "                # print(\"no_imgs\", no_imgs)\n",
    "                # print(\"class_label_len\", class_label_len)\n",
    "                sample_name=\"sample\"+str(sample)\n",
    "                image_nums.append(image_num)\n",
    "                # print(\"dumb2\", dumb2)\n",
    "                # print(\"label_name\", label_name)\n",
    "                # print(\"[dumb[label_name]\", dumb[label_name])\n",
    "                #dumb.reset_index(drop=True, inplace=True)\n",
    "                sample_dict[sample_name] = pd.concat([sample_dict[sample_name], dumb2])\n",
    "        # self.draw_dirichlet_plot(10, number_of_samples,image_nums, alpha)\n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iid_subsamples(sample_dict, x_data, y_data, x_name, y_name):\n",
    "    x_data_dict= dict()\n",
    "    y_data_dict= dict()\n",
    "    \n",
    "    for i in range(len(sample_dict)):  ### len(sample_dict)= number of samples\n",
    "        xname= x_name+str(i)\n",
    "        yname= y_name+str(i)\n",
    "        sample_name=\"sample\"+str(i)\n",
    "        \n",
    "        indices=np.sort(np.array(sample_dict[sample_name][\"i\"]))\n",
    "        \n",
    "        x_info= x_data[indices,:]\n",
    "        x_data_dict.update({xname : x_info})\n",
    "        \n",
    "        y_info= y_data[indices]\n",
    "        y_data_dict.update({yname : y_info})\n",
    "        \n",
    "    return x_data_dict, y_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "### <span style=\"background-color:#F087F9\"> Classification Model </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2nn, self).__init__()\n",
    "        self.fc1=nn.Linear(784,200)\n",
    "        self.fc2=nn.Linear(200,200)\n",
    "        self.fc3=nn.Linear(200,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        prediction = output.argmax(dim=1, keepdim=True)\n",
    "        correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "        \n",
    "\n",
    "    return train_loss / len(train_loader), correct/len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criterion(output, target).item()\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    correct /= len(test_loader.dataset)\n",
    "\n",
    "    return (test_loss, correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "### <span style=\"background-color:#F087F9\"> Functions for Federated Averaging </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_optimizer_criterion_dict(number_of_samples):\n",
    "    model_dict = dict()\n",
    "    optimizer_dict= dict()\n",
    "    criterion_dict = dict()\n",
    "    \n",
    "    for i in range(number_of_samples):\n",
    "        model_name=\"model\"+str(i)\n",
    "        model_info=Net2nn()\n",
    "        model_dict.update({model_name : model_info })\n",
    "        \n",
    "        optimizer_name=\"optimizer\"+str(i)\n",
    "        optimizer_info = torch.optim.SGD(model_info.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        optimizer_dict.update({optimizer_name : optimizer_info })\n",
    "        \n",
    "        criterion_name = \"criterion\"+str(i)\n",
    "        criterion_info = nn.CrossEntropyLoss()\n",
    "        criterion_dict.update({criterion_name : criterion_info})\n",
    "        \n",
    "    return model_dict, optimizer_dict, criterion_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_weights(model_dict, number_of_samples):\n",
    "   \n",
    "    fc1_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc1.weight.shape)\n",
    "    fc1_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc1.bias.shape)\n",
    "    \n",
    "    fc2_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc2.weight.shape)\n",
    "    fc2_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc2.bias.shape)\n",
    "    \n",
    "    fc3_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc3.weight.shape)\n",
    "    fc3_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc3.bias.shape)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "    \n",
    "        for i in range(number_of_samples):\n",
    "            fc1_mean_weight += model_dict[name_of_models[i]].fc1.weight.data.clone()\n",
    "            fc1_mean_bias += model_dict[name_of_models[i]].fc1.bias.data.clone()\n",
    "        \n",
    "            fc2_mean_weight += model_dict[name_of_models[i]].fc2.weight.data.clone()\n",
    "            fc2_mean_bias += model_dict[name_of_models[i]].fc2.bias.data.clone()\n",
    "        \n",
    "            fc3_mean_weight += model_dict[name_of_models[i]].fc3.weight.data.clone()\n",
    "            fc3_mean_bias += model_dict[name_of_models[i]].fc3.bias.data.clone()\n",
    "\n",
    "        \n",
    "        fc1_mean_weight =fc1_mean_weight/number_of_samples\n",
    "        fc1_mean_bias = fc1_mean_bias/ number_of_samples\n",
    "    \n",
    "        fc2_mean_weight =fc2_mean_weight/number_of_samples\n",
    "        fc2_mean_bias = fc2_mean_bias/ number_of_samples\n",
    "    \n",
    "        fc3_mean_weight =fc3_mean_weight/number_of_samples\n",
    "        fc3_mean_bias = fc3_mean_bias/ number_of_samples\n",
    "    \n",
    "    return fc1_mean_weight, fc1_mean_bias, fc2_mean_weight, fc2_mean_bias, fc3_mean_weight, fc3_mean_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,model_dict, number_of_samples):\n",
    "    fc1_mean_weight, fc1_mean_bias, fc2_mean_weight, fc2_mean_bias, fc3_mean_weight, fc3_mean_bias = get_averaged_weights(model_dict, number_of_samples=number_of_samples)\n",
    "    with torch.no_grad():\n",
    "        main_model.fc1.weight.data = fc1_mean_weight.data.clone()\n",
    "        main_model.fc2.weight.data = fc2_mean_weight.data.clone()\n",
    "        main_model.fc3.weight.data = fc3_mean_weight.data.clone()\n",
    "\n",
    "        main_model.fc1.bias.data = fc1_mean_bias.data.clone()\n",
    "        main_model.fc2.bias.data = fc2_mean_bias.data.clone()\n",
    "        main_model.fc3.bias.data = fc3_mean_bias.data.clone() \n",
    "    return main_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_local_and_merged_model_performance(number_of_samples):\n",
    "    accuracy_table=pd.DataFrame(data=np.zeros((number_of_samples,3)), columns=[\"sample\", \"local_ind_model\", \"merged_main_model\"])\n",
    "    for i in range (number_of_samples):\n",
    "    \n",
    "        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n",
    "        test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        individual_loss, individual_accuracy = validation(model, test_dl, criterion)\n",
    "        main_loss, main_accuracy =validation(main_model, test_dl, main_criterion )\n",
    "    \n",
    "        accuracy_table.loc[i, \"sample\"]=\"sample \"+str(i)\n",
    "        accuracy_table.loc[i, \"local_ind_model\"] = individual_accuracy\n",
    "        accuracy_table.loc[i, \"merged_main_model\"] = main_accuracy\n",
    "\n",
    "    return accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples):\n",
    "    with torch.no_grad():\n",
    "        for i in range(number_of_samples):\n",
    "\n",
    "            model_dict[name_of_models[i]].fc1.weight.data =main_model.fc1.weight.data.clone()\n",
    "            model_dict[name_of_models[i]].fc2.weight.data =main_model.fc2.weight.data.clone()\n",
    "            model_dict[name_of_models[i]].fc3.weight.data =main_model.fc3.weight.data.clone() \n",
    "            \n",
    "            model_dict[name_of_models[i]].fc1.bias.data =main_model.fc1.bias.data.clone()\n",
    "            model_dict[name_of_models[i]].fc2.bias.data =main_model.fc2.bias.data.clone()\n",
    "            model_dict[name_of_models[i]].fc3.bias.data =main_model.fc3.bias.data.clone() \n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train_end_node_process(number_of_samples):\n",
    "    for i in range (number_of_samples): \n",
    "\n",
    "        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#         valid_ds = TensorDataset(x_valid_dict[name_of_x_valid_sets[i]], y_valid_dict[name_of_y_valid_sets[i]])\n",
    "#         valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)\n",
    "        \n",
    "        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n",
    "        test_dl = DataLoader(test_ds, batch_size= batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        print(\"Subset\" ,i)\n",
    "        for epoch in range(numEpoch):        \n",
    "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
    "#             valid_loss, valid_accuracy = validation(model, valid_dl, criterion)\n",
    "            test_loss, test_accuracy = validation(model, test_dl, criterion)\n",
    "    \n",
    "            print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.5f}\".format(train_accuracy) + \" | test accuracy: {:7.5f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train_end_node_process_without_print(number_of_samples, sample_list, iteration, plot_indiv, plot_glob, layer, mode, global_table):\n",
    "    initial_result = create_similiarity_matrix(model_dict, layer, 0, mode)\n",
    "    # plot_matrix(initial_result, layer, iteration, mode, 0, file_location=\"Plots/\")\n",
    "    global_table.append([iteration, 0, layer, mode, initial_result])\n",
    "    \n",
    "    for epoch in range(1, numEpoch+1): \n",
    "        for i in range (number_of_samples): \n",
    "            train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n",
    "            train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n",
    "            test_dl = DataLoader(test_ds, batch_size= batch_size * 2)\n",
    "\n",
    "            model=model_dict[name_of_models[i]]\n",
    "            criterion=criterion_dict[name_of_criterions[i]]\n",
    "            optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "            \n",
    "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
    "            test_loss, test_accuracy = validation(model, test_dl, criterion)\n",
    "        \n",
    "        if plot_indiv is True:\n",
    "            for sample in sample_list:\n",
    "                plot_node_weights(model_dict, sample[0], sample[1], iteration)\n",
    "                \n",
    "        if plot_glob is True:\n",
    "            iteration_result = create_similiarity_matrix(model_dict, layer, iteration, mode)\n",
    "            # plot_matrix(iteration_result, layer, iteration, mode, epoch, file_location=\"Plots/\")\n",
    "            global_table.append([iteration, epoch, layer, mode, iteration_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train_end_node_process_print_some(number_of_samples, print_amount, sample_list, iteration):\n",
    "    for i in range (number_of_samples): \n",
    "\n",
    "        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n",
    "        test_dl = DataLoader(test_ds, batch_size= batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        if i<print_amount:\n",
    "            print(\"Subset\" ,i)\n",
    "            \n",
    "        for epoch in range(numEpoch):\n",
    "        \n",
    "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
    "            test_loss, test_accuracy = validation(model, test_dl, criterion)\n",
    "            \n",
    "            if i<print_amount:        \n",
    "                print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.5f}\".format(train_accuracy) + \" | test accuracy: {:7.5f}\".format(test_accuracy)) \n",
    "        for sample in sample_list:\n",
    "            plot_node_weights(model_dict, sample[0], sample[1], iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add visualization code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(result, layer, iteration, mode, epoch, vmin, vmax, num_ticks, file_location=\"Plots/\"):\n",
    "    matplotlib.use('Agg')\n",
    "    labels = list(range(0, number_of_samples))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,15))\n",
    "    # cax = ax.matshow(result, interpolation='nearest')\n",
    "    if mode == 'cos':\n",
    "        colormap = 'OrRd'\n",
    "    elif mode == 'l2':\n",
    "        colormap = 'YlGnBu'\n",
    "    \n",
    "    cax = ax.imshow(result, vmin = vmin, vmax = v_max, cmap=colormap, interpolation='nearest') # cmap='YlGnBu', 'OrRd'    \n",
    "    # ax.grid(True)\n",
    "    plt.title('100 FL Clients Similarity Matrix IID' + \" \" + str(mode) + \" \" + \"iter\" + str(iteration) + \"_\" + \"epoch\" + str(epoch), fontsize = 15)\n",
    "    plt.xticks(range(number_of_samples), labels, rotation=90);\n",
    "    plt.yticks(range(number_of_samples), labels);\n",
    "    # ticks = np.linspace(vmin, vmax, num_ticks)\n",
    "    ticks = np.arange(v_min, v_max, round((v_max - v_min)/(num_ticks-1), 2))\n",
    "    ticks = np.append(ticks, v_max)\n",
    "    cbar = fig.colorbar(cax, ax=ax)\n",
    "\n",
    "    font_size = 10 # Adjust as appropriate.\n",
    "    cbar.set_ticks(ticks)\n",
    "    cbar.ax.tick_params(labelsize=font_size)\n",
    "    \n",
    "    # plt.show()\n",
    "    \n",
    "    # create a time stamp\n",
    "    today = date.today().strftime('%Y%m%d')\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H-%M-%S\")\n",
    "    \n",
    "    plt_name = \"Glob\" + \"_\" + layer + \"_\"  + \"I\" + str(iteration) + \"_\" +\\\n",
    "                \"E\" + str(epoch) + \"_\" + str(today) + \"_\" + str(current_time) + \".png\"\n",
    "    \n",
    "    node_folder = file_location + layer + \"_\" + str(mode)\n",
    "    \n",
    "    if not os.path.exists(node_folder):\n",
    "        os.makedirs(node_folder)\n",
    "    \n",
    "    plt.savefig(node_folder + '/' + plt_name)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_node_weights(model_dict, layer, selected_weight, iteration, file_location=\"Plots/\"):\n",
    "    # create an array of the weight values|\n",
    "    sample_weights = []\n",
    "    sample_bias = []\n",
    "    for i in range (number_of_samples):\n",
    "        current_model = \"model\" + str(i)\n",
    "        w_local = getattr(model_dict[current_model], layer).weight[selected_weight[0],selected_weight[1]].detach().numpy()\n",
    "        b_local = getattr(model_dict[current_model], layer).bias[selected_weight[0]].detach().numpy()\n",
    "        \n",
    "        sample_weights.append(w_local.tolist())\n",
    "        sample_bias.append(b_local.tolist())\n",
    "\n",
    "    num_bins = int(number_of_samples/4)\n",
    "\n",
    "    # process the data with GaussianMixture model\n",
    "    sample_weights = np.asarray(sample_weights)\n",
    "    sample_weights = sample_weights.reshape(len(sample_weights), 1)\n",
    "    sample_bias = np.asarray(sample_bias)\n",
    "    sample_bias = sample_bias.reshape(len(sample_bias), 1)    \n",
    "\n",
    "    # Create a histgram\n",
    "    # fig, ax = plt.subplots()\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, sharey=False, figsize=(10, 15))\n",
    "\n",
    "    n, bins, patches = ax1.hist(sample_weights, num_bins, \n",
    "                            density = 1, \n",
    "                            color ='darkolivegreen',\n",
    "                            alpha = 0.7)\n",
    "    \n",
    "    mu1 = np.mean(sample_weights)\n",
    "    fig.set_facecolor(\"lightgray\")\n",
    "    ax1.axvline(mu1, color='blue', linestyle='dashed', linewidth=1)\n",
    "    # min_ylim, max_ylim = plt.ylim()\n",
    "    plt.suptitle('IID Layer of: ' + layer + ', Random Weight: ' +  str(selected_weight) + ', Iter ' + str(iteration))\n",
    "    ax1.set_title('Weights Mean: {:.6f}'.format(mu1))\n",
    "    \n",
    "    n, bins, patches = ax2.hist(sample_bias, num_bins, \n",
    "                            density = 1, \n",
    "                            color ='brown',\n",
    "                            alpha = 0.7)\n",
    "    \n",
    "    mu2 = np.mean(sample_bias)\n",
    "    ax2.axvline(mu2, color='blue', linestyle='dashed', linewidth=1)\n",
    "    ax2.set_title('Bias Mean: {:.6f}'.format(mu2))    \n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    # create a time stamp\n",
    "    today = date.today().strftime('%Y%m%d')\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H-%M-%S\")\n",
    "    \n",
    "    # plt.show() \n",
    "    plt_name = layer + \"_\" + str(selected_weight[0]) + \"_\" + str(selected_weight[1]) + \"_I_\" + \\\n",
    "    str(iteration) + \"_\" + str(today) + \"_\" + str(current_time) + \".png\"\n",
    "    \n",
    "    node_folder = file_location + layer + \"_\" + str(selected_weight[0]) + \"_\" + str(selected_weight[1])\n",
    "    \n",
    "    if not os.path.exists(node_folder):\n",
    "        os.makedirs(node_folder)\n",
    "    \n",
    "    plt.savefig(node_folder + '/' + plt_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling based on parameters\n",
    "def random_sampling_nodes(model, each_layer_sample_num):\n",
    "    layers = []\n",
    "    for name, layer in model.named_modules():\n",
    "        if name != \"\":\n",
    "            dnn_layer = getattr(model, name)\n",
    "            layers.append([name, [dnn_layer.weight.size()[0], dnn_layer.weight.size()[1]], dnn_layer.bias.size()[0]])\n",
    "    print(*layers,sep='\\n')\n",
    "    \n",
    "    if len(each_layer_sample_num)!=len(layers):\n",
    "        print(\"each_layer_sample_num list's length not equal to model layer list\")\n",
    "        return(-1)\n",
    "    else:\n",
    "        weights_sample = []\n",
    "        for i in range(len(layers)):\n",
    "            for j in range (each_layer_sample_num[i]):\n",
    "                random_weight = [np.random.randint(layers[i][1][0]), np.random.randint(layers[i][1][1])]\n",
    "                print(\"random_weight:\", random_weight)\n",
    "                weights_sample.append([layers[i][0], random_weight])\n",
    "    return weights_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2dist(p1, p2):\n",
    "    \"\"\"L2 distance between p1, p2, each of which is a tensor\"\"\"\n",
    "    \n",
    "    return torch.dist(p1, p2, p=2)\n",
    "    \n",
    "\n",
    "def cosine_similarity(grad1, grad2, normalized=False):\n",
    "\t\"\"\"\n",
    "\tInput: two sets of gradients of the same shape\n",
    "\tOutput range: [-1, 1]\n",
    "\t\"\"\"\n",
    "\n",
    "\tcos_sim = F.cosine_similarity(torch.flatten(grad1), torch.flatten(grad2), 0, 1e-10) \n",
    "\tif normalized:\n",
    "\t\treturn (cos_sim + 1) / 2.0\n",
    "\telse:\n",
    "\t\treturn cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the similiarity matrix of the avg distance or similiarity between clients\n",
    "def create_similiarity_matrix(model_dict, layer, iteration, mode):\n",
    "    # create an array of the weight values\n",
    "    if mode not in [\"l2\", \"cos\"]:\n",
    "        raise Error(\"model has to be in 'l2', 'cos'.\")\n",
    "    \n",
    "    sample_weights = []\n",
    "    for i in range (number_of_samples):\n",
    "        current_model = \"model\" + str(i)\n",
    "        w_i = getattr(model_dict[current_model], layer).weight\n",
    "        sample_weights.append(w_i)\n",
    "    \n",
    "    resultTable = []\n",
    "    for i in range(len(sample_weights)):\n",
    "        distances = []\n",
    "        for j in range(len(sample_weights)):\n",
    "            if mode == \"l2\":\n",
    "                distances.append(l2dist(sample_weights[i], sample_weights[j]).item())\n",
    "            elif mode == \"cos\":\n",
    "                distances.append(cosine_similarity(sample_weights[i], sample_weights[j], False).item())\n",
    "        resultTable.append(distances)\n",
    "        \n",
    "    # print(\"resultTable[0]\", resultTable[0])    \n",
    "    return(resultTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid,x_test, y_test = map(torch.tensor, (x_train, y_train, x_valid, y_valid, x_test, y_test))\n",
    "number_of_samples=100\n",
    "learning_rate = 0.01\n",
    "numEpoch = 10\n",
    "batch_size = 32\n",
    "momentum = 0.9\n",
    "dirichlet_alpha = 0.2\n",
    "\n",
    "train_amount=4500\n",
    "valid_amount=900\n",
    "test_amount=900\n",
    "print_amount=3\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "cuda_cka = CudaCKA(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "\n",
    "### <span style=\"background-color:#F087F9\"> Let's examine what would the performance of the centralized model be if the data were not distributed to nodes at all? </span>   \n",
    "\n",
    "The model used in this example is very simple, different things can be done to improve model performance, such as using more complex models, increasing epoch or hyperparameter tuning. However, the purpose here is to compare the performance of the main model that is formed by combining the parameters of the local models trained on their own data with a centralized model that trained on all training data. In this way, we can gain insight into the capacity of federated learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_model = Net2nn()\n",
    "centralized_optimizer = torch.optim.SGD(centralized_model.parameters(), lr=0.01, momentum=0.9)\n",
    "centralized_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)\n",
    "\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"------ Centralized Model ------\")\n",
    "# for epoch in range(numEpoch):\n",
    "#     central_train_loss, central_train_accuracy = train(centralized_model, train_dl, centralized_criterion, centralized_optimizer)\n",
    "#     central_test_loss, central_test_accuracy = validation(centralized_model, test_dl, centralized_criterion)\n",
    "    \n",
    "#     print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.4f}\".format(central_train_accuracy) + \" | test accuracy: {:7.4f}\".format(central_test_accuracy))\n",
    "\n",
    "# print(\"------ Training finished ------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------------\n",
    "-----------------\n",
    "**Data is distributed to nodes**\n",
    "\n",
    "<!-- ### <span style=\"background-color:#F087F9\"> Datanın nodelara dağıtılması </span>    -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IID and 2 Class group Non-IID\n",
    "# label_dict_train=split_and_shuffle_labels(y_data=y_train, seed=1, amount=train_amount) \n",
    "# sample_dict_train= get_subsamples_indices(label_dict=label_dict_train, number_of_samples=number_of_samples, amount=train_amount, NonIID = True)\n",
    "# x_train_dict, y_train_dict = create_iid_subsamples(sample_dict=sample_dict_train, x_data=x_train, y_data=y_train, x_name=\"x_train\", y_name=\"y_train\")\n",
    "\n",
    "\n",
    "# label_dict_valid = split_and_shuffle_labels(y_data=y_valid, seed=1, amount=train_amount) \n",
    "# sample_dict_valid =  get_subsamples_indices(label_dict=label_dict_valid, number_of_samples=number_of_samples, amount=valid_amount, NonIID = True)\n",
    "# x_valid_dict, y_valid_dict = create_iid_subsamples(sample_dict=sample_dict_valid, x_data=x_valid, y_data=y_valid, x_name=\"x_valid\", y_name=\"y_valid\")\n",
    "\n",
    "# label_dict_test = split_and_shuffle_labels(y_data=y_test, seed=1, amount=test_amount) \n",
    "# sample_dict_test =  get_subsamples_indices(label_dict=label_dict_test, number_of_samples=number_of_samples, amount=test_amount, NonIID = True)\n",
    "# x_test_dict, y_test_dict = create_iid_subsamples(sample_dict=sample_dict_test, x_data=x_test, y_data=y_test, x_name=\"x_test\", y_name=\"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-IID with Dirichlet distribution\n",
    "\n",
    "label_dict_train=split_and_shuffle_labels(y_data=y_train, seed=1, amount=train_amount) \n",
    "sample_dict_train= get_subsamples_indices_new(label_dict=label_dict_train, number_of_samples=number_of_samples, amount=train_amount, NonIID = True, alpha=dirichlet_alpha)\n",
    "x_train_dict, y_train_dict = create_iid_subsamples(sample_dict=sample_dict_train, x_data=x_train, y_data=y_train, x_name=\"x_train\", y_name=\"y_train\")\n",
    "\n",
    "\n",
    "label_dict_valid = split_and_shuffle_labels(y_data=y_valid, seed=1, amount=train_amount) \n",
    "sample_dict_valid =  get_subsamples_indices(label_dict=label_dict_valid, number_of_samples=number_of_samples, amount=valid_amount, NonIID = False)\n",
    "x_valid_dict, y_valid_dict = create_iid_subsamples(sample_dict=sample_dict_valid, x_data=x_valid, y_data=y_valid, x_name=\"x_valid\", y_name=\"y_valid\")\n",
    "\n",
    "label_dict_test = split_and_shuffle_labels(y_data=y_test, seed=1, amount=test_amount) \n",
    "sample_dict_test =  get_subsamples_indices(label_dict=label_dict_test, number_of_samples=number_of_samples, amount=test_amount, NonIID = False)\n",
    "x_test_dict, y_test_dict = create_iid_subsamples(sample_dict=sample_dict_test, x_data=x_test, y_data=y_test, x_name=\"x_test\", y_name=\"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([360, 784]) torch.Size([360])\n",
      "torch.Size([90, 784]) torch.Size([90])\n",
      "torch.Size([90, 784]) torch.Size([90])\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x_train_dict[\"x_train1\"].shape, y_train_dict[\"y_train1\"].shape)\n",
    "print(x_valid_dict[\"x_valid1\"].shape, y_valid_dict[\"y_valid1\"].shape) \n",
    "print(x_test_dict[\"x_test1\"].shape, y_test_dict[\"y_test1\"].shape)\n",
    "\n",
    "num_index = np.random.randint(test_amount/number_of_samples*10)\n",
    "plt.imshow(x_test_dict[\"x_test0\"][num_index].reshape((28,28)), cmap=\"gray\")\n",
    "print(y_test_dict[\"y_test0\"][num_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main model is created**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model = Net2nn()\n",
    "main_optimizer = torch.optim.SGD(main_model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "main_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models,optimizers and loss functions in nodes are defined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict, optimizer_dict, criterion_dict = create_model_optimizer_criterion_dict(number_of_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keys of dicts are being made iterable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_x_train_sets=list(x_train_dict.keys())\n",
    "name_of_y_train_sets=list(y_train_dict.keys())\n",
    "name_of_x_valid_sets=list(x_valid_dict.keys())\n",
    "name_of_y_valid_sets=list(y_valid_dict.keys())\n",
    "name_of_x_test_sets=list(x_test_dict.keys())\n",
    "name_of_y_test_sets=list(y_test_dict.keys())\n",
    "\n",
    "name_of_models=list(model_dict.keys())\n",
    "name_of_optimizers=list(optimizer_dict.keys())\n",
    "name_of_criterions=list(criterion_dict.keys())\n",
    "\n",
    "# print(name_of_x_train_sets)\n",
    "# print(name_of_y_train_sets)\n",
    "# print(name_of_x_valid_sets)\n",
    "# print(name_of_y_valid_sets)\n",
    "# print(name_of_x_test_sets)\n",
    "# print(name_of_y_test_sets)\n",
    "# print(\"\\n ------------\")\n",
    "# print(name_of_models)\n",
    "# print(name_of_optimizers)\n",
    "# print(name_of_criterions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0531,  0.0352, -0.0107,  0.0613, -0.0133]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 2.5117e-02,  8.9198e-05, -2.9099e-03, -3.7021e-02, -3.8768e-02]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(main_model.fc2.weight[0:1,0:5])\n",
    "print(model_dict[\"model1\"].fc2.weight[0:1,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters of main model are sent to nodes**  \n",
    "Since the parameters of the main model and parameters of all local models in the nodes are randomly initialized, all these parameters will be different from each other. For this reason, the main model sends its parameters to the nodes before the training of local models in the nodes begins. You can check the weights below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict=send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0531,  0.0352, -0.0107,  0.0613, -0.0133]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0531,  0.0352, -0.0107,  0.0613, -0.0133]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(main_model.fc2.weight[0:1,0:5])\n",
    "print(model_dict[\"model1\"].fc2.weight[0:1,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_layer_list = [0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fc1', [200, 784], 200]\n",
      "['fc2', [200, 200], 200]\n",
      "['fc3', [10, 200], 10]\n",
      "random_weight: [2, 106]\n"
     ]
    }
   ],
   "source": [
    "# samples for individual weight location view\n",
    "sample_t = random_sampling_nodes(main_model, each_layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fc3', [2, 106]]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip the seperate first iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models in the nodes are trained**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_train_end_node_process()\n",
    "# start_train_end_node_process_print_some(number_of_samples, print_amount, sample_t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As you can see, wieghts of local models are updated after training process\n",
    "# print(main_model.fc2.weight[0,0:5])\n",
    "# print(model_dict[\"model1\"].fc2.weight[0,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare the performance of federated main model, individual local models and centralized model  \n",
    "\n",
    "**Federated main model vs individual local models before 1st iteration (on distributed test set)**  \n",
    "Since main model is randomly initialized and no action taken on it yet, its performance is very poor. Please before_acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before_acc_table=compare_local_and_merged_model_performance(number_of_samples=number_of_samples)\n",
    "# before_test_loss, before_test_accuracy = validation(main_model, test_dl, main_criterion)\n",
    "\n",
    "# main_model= set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,model_dict, number_of_samples) \n",
    "\n",
    "# after_acc_table=compare_local_and_merged_model_performance(number_of_samples=number_of_samples)\n",
    "# after_test_loss, after_test_accuracy = validation(main_model, test_dl, main_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Federated main model vs individual local models before FedAvg first iteration\")\n",
    "# before_acc_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Federated main model vs individual local models after FedAvg first iteration\")\n",
    "# after_acc_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Federated main model vs centralized model before 1st iteration (on all test data)**  \n",
    "Please be aware that the centralized model gets approximately %98 accuracy on all test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Before 1st iteration main model accuracy on all test data: {:7.4f}\".format(before_test_accuracy))\n",
    "# print(\"After 1st iteration main model accuracy on all test data: {:7.4f}\".format(after_test_accuracy))\n",
    "# print(\"Centralized model accuracy on all test data: {:7.4f}\".format(central_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a single iteration, we can send the weights of the main model back to the nodes and repeat the above steps.\n",
    "Now let's check how the performance of the main model improves when we repeat the iteration 10 more times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_records = []\n",
    "test_accuracy_records = []\n",
    "global_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 : main_model accuracy on all test data:  0.6967\n",
      "Iteration 2 : main_model accuracy on all test data:  0.8089\n",
      "Iteration 3 : main_model accuracy on all test data:  0.8488\n",
      "Iteration 4 : main_model accuracy on all test data:  0.8639\n",
      "Iteration 5 : main_model accuracy on all test data:  0.8711\n",
      "Iteration 6 : main_model accuracy on all test data:  0.8745\n",
      "Iteration 7 : main_model accuracy on all test data:  0.8769\n",
      "Iteration 8 : main_model accuracy on all test data:  0.8805\n",
      "Iteration 9 : main_model accuracy on all test data:  0.8845\n",
      "Iteration 10 : main_model accuracy on all test data:  0.8858\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model_dict=send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)\n",
    "    start_train_end_node_process_without_print(number_of_samples, sample_t, i+1, False, True, 'fc3', 'cos', global_results)\n",
    "    \n",
    "    main_model= set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,model_dict, number_of_samples) \n",
    "    test_loss, test_accuracy = validation(main_model, test_dl, main_criterion)\n",
    "    test_loss_records.append(test_loss)\n",
    "    test_accuracy_records.append(test_accuracy)\n",
    "    print(\"Iteration\", str(i+1), \": main_model accuracy on all test data: {:7.4f}\".format(test_accuracy))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 0,  ..., 0, 5, 0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dict['y_train0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dict['x_train0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find v_min and v_max globally aftert the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_master = []\n",
    "for i in range(len(global_results)):\n",
    "    matrix_master.append(global_results[i][-1])\n",
    "    \n",
    "matrix_master = np.asarray(matrix_master)\n",
    "v_min = np.amin(matrix_master)\n",
    "v_max = np.amax(matrix_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5294433832168579, 1.0000003576278687)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(v_min, v_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all iteration - epochs with saved data in global_results\n",
    "for i in range(len(global_results)):\n",
    "    iteration = global_results[i][0]\n",
    "    epoch = global_results[i][1]\n",
    "    layer = global_results[i][2]\n",
    "    mode = global_results[i][3]\n",
    "    result_matrix = global_results[i][-1]\n",
    "    \n",
    "    plot_matrix(result_matrix, layer, iteration, mode, epoch, v_min, v_max, num_ticks=9, file_location=\"Plots/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = list(range(0, 99))\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(20,20))\n",
    "# cax = ax.matshow(global_results[9], interpolation='nearest')\n",
    "# ax.grid(True)\n",
    "\n",
    "# plt.title('100 FL Clients Similarity Matrix IID cos-Iter 2', fontsize = 20)\n",
    "# plt.xticks(range(99), labels, rotation=90);\n",
    "# plt.yticks(range(99), labels);\n",
    "# # cbar = fig.colorbar(cax, ticks=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, .75,.8,.85,.90,.95,1])\n",
    "# cbar = fig.colorbar(cax, ticks=[0.95, 0.96, 0.97, 0.98, 0.99, 1], fraction=0.045)\n",
    "# font_size = 10 # Adjust as appropriate.\n",
    "# cbar.ax.tick_params(labelsize=font_size)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8733590712213213,\n",
       " 0.973770268024153,\n",
       " 0.5894867441836437,\n",
       " 0.4734129271689494,\n",
       " 0.4310305334010701,\n",
       " 0.40848814726919885,\n",
       " 0.39727077217903106,\n",
       " 0.39006205045493547,\n",
       " 0.38362219337682435,\n",
       " 0.3797505932510089]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_records\n",
    "test_loss_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location=\"Plots/\"\n",
    "layer = 'fc3'\n",
    "mode = 'cos'\n",
    "node_folder = file_location + layer + \"_\" + str(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plots/fc3_cos'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot lines of loss and accuracy\n",
    "plt.clf()\n",
    "plt.plot(test_accuracy_records)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('iteration')\n",
    "plt.legend(['Validation'], loc='upper left')\n",
    "plt_name = 'Test_Accuracy_Records'\n",
    "plt.savefig(node_folder + '/' + plt_name)\n",
    "\n",
    "# summarize history for loss\n",
    "plt.clf()\n",
    "plt.plot(test_loss_records, color='orange')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.legend(['Validation'], loc='upper left')\n",
    "plt_name = 'Test_Loss_Records'\n",
    "plt.savefig(node_folder + '/' + plt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the centralized model was calculated as approximately 98%. The accuracy of the main model obtained by FedAvg method started from 85% and improved to 94%. In this case, we can say that although the main model obtained by FedAvg method was trained without seeing the data, its performance cannot be underestimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create video\n",
    "from moviepy.editor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_video(image_folder_path: str, fps, extension:str, video_name:str, output_format:str):\n",
    "    \n",
    "    import os\n",
    "    import moviepy.video.io.ImageSequenceClip\n",
    "    \n",
    "    images = [image_folder_path+'/'+img for img in os.listdir(image_folder_path) if img.endswith(extension)]\n",
    "    images.sort(key=lambda s: os.path.getmtime(os.path.join( s)))\n",
    "    \n",
    "    # print(images)\n",
    "    movie_clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(images, fps)\n",
    "    movie_clip.write_videofile(video_name+output_format,codec=\"libx264\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = \"fc3\" + \"_\" + \"l2\"\n",
    "images_to_video(\"Plots/\" + str(layer_name), 6, \".png\", layer_name, \".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_to_video(\"Plots/\" + \"fc1_18_106\", 24, \".png\", \"fc1_18_106\", \".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sample_t:\n",
    "    node_name = s[0]+\"_\"+ str(s[1][0])+\"_\"+str(s[1][1])\n",
    "    images_to_video(\"Plots/\" + str(node_name), 24, \".png\", node_name, \".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_name = \"fc2_21_67\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video fc2_21_67.mp4.\n",
      "Moviepy - Writing video fc2_21_67.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready fc2_21_67.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "images_to_video(\"Plots/\" + str(node_name), 24, \".png\", node_name, \".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
